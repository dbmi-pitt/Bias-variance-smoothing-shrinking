
Dr. Who is not confident in either Dr. Split or Dr. Lump.  Maybe one’s right ($\phi  = Split$ ), maybe the other ( $\phi  = Lump$). Here is a prior that might represent this view:;

\[\pi _{Who}^{}({\bf{p}}) = \pi _{Who}^{}(\phi  = Split)\pi _{Split}^{}({\bf{p}}) + \pi _{Who}^{}(\phi  = Lump)\pi _{Lump}^{}({\bf{p}}).\]
 
NOTE: This marginalizes out (sums over) the nuisance parameter $\phi$ over the joint distribution of ( ${p_{R.D}},\phi$)!  


Briefly Bayes Theorem without a nuisance parameter is:

\[\begin{array}{l}
\quad [\theta |X] = \frac{{[X,\theta ]}}{X} = \frac{{[X,\theta ]}}{{\int\limits_\theta  {} [X,\theta ]}} = \frac{{[X|\theta ][\theta ]}}{{\int\limits_\theta  {} [X,\theta ]}}\\
\end{array}\]

And Bayes Theorem with a nuisance parameter is:

\[\begin{array}{l}
\quad [\theta |X] = \sum\limits_\phi  {} [\theta ,\phi |X] = \frac{{\sum\limits_\phi  {} [X,\theta ,\phi ]}}{{\sum\limits_{\phi ,\theta } {} [X,\theta ,\phi ]}}
\end{array}\]

Here the nuisance parameter $\phi$ is: whose opinion is right, $Split$ or $Lump$?

(For more details on Bayes Theorem, including conditioning and marginalizing, see 
`r linkoutLink(fileName = 'bayes_decision_analysis.pdf',
linkouttext='here')`). 


Then Dr. Who’s posterior is:
 \[\pi _{Who}^*({p_{R.D}}) = \pi _{Who}^*(\phi  = Split)\pi _{Split}^*({p_{R.D}}) + \pi _{Who}^*(\phi  = Lump)\pi _{Lump}^*({p_{R.D}})\]
 
where
 \[\pi _{Who}^*(\phi  = Split) = \frac{{\pi (Split){m_{Split}}}}{{\pi (Split){m_{Split}} + \pi (Lump){m_{Lump}}}},\]
and the $m$ values are the respective marginal distributions of the data  $({n_{RD}},{n_{RL}},{n_{ND}},{n_{NL}})$ if you knew $\phi$ but not the parameters  --  conditional $\phi$ and marginal over ${p_{R.D}}$.  

```{r}
TextQuestion("If Dr. Who gives Dr. Lump and Dr. Split equal weight BEFORE seeing the data, is this still true AFTER seeing the data?
")
```

##### Marginal probability for each hypothesis Split and Lump

If *Split* is correct, then the (marginal) probability of getting the data we observed is 
`r output$mSplit = renderText({
  signif(digits=3, mSplit(rValues$DLdata)); 
  })
  textOutput('mSplit', inline=TRUE)
`.


```{r}
conditionalPanelWithCheckbox(
  labelString = 'Equations for Dr. Split\'s marginal probability', 
  filename = 'DrSplitEquation.Rmd',
  html='',
  initialValue=FALSE
)
```

If *Lump* is correct, then the (marginal) probability of getting the data we observed is:
`r output$mLump = renderText({
  signif(digits=3, mLump(rValues$DLdata)); 
  })
  textOutput('mLump', inline=TRUE)
`.

```{r}
conditionalPanelWithCheckbox(
  labelString = 'Equations for Dr. Lump\'s marginal probability', 
  filename = 'DrLumpEquation.Rmd',
  html='',
  initialValue=FALSE
)
```

Here is the code if you are interested:

```{r}
conditionalPanelWithCheckbox(
  labelString = 'Code for the Lump and Split marginal probabilities',
  html=
    div(
              HTML(gsub('  ', '&nbsp;&nbsp;',
                        paste(readLines(con='DrWhoBayesFactor.R'),
                    collapse='<br>\n')))
  ),
  initialValue=FALSE
)
```

The posterior distribution for Dr. Who marginalizes over $\phi$. It is a mixture, as graphed here.

```{r}
output$whoMixturePlot = 
  renderPlot(expr =  {
    pSeq = seq(0,1, length=100)
    par(mfrow=c(1,2))
    prior.s = dbeta(pSeq, 1, 1)
    prior.l = dbeta(pSeq, 2, 2)
    prior.w = (1/2) * prior.s + (1/2) * prior.l
    plot(pSeq, prior.s, col='blue', type='l',
         xlab='probability', ylab='density',
         ylim=c(0,15),
         main='Priors') 
    lines(pSeq, prior.l,  col='red')
    lines(pSeq, prior.w,  col='darkgreen', lwd=2)
    everyTenth = (1:length(pSeq)) %% 10 == 0
    points(pSeq[everyTenth], prior.s[everyTenth], pch='S', col='blue')
    points(pSeq[everyTenth], prior.l[everyTenth], pch='L', col='red')
    points(pSeq[everyTenth], prior.w[everyTenth], pch='W', col='darkgreen')
    Sexpression = as.expression(
      bquote("S:  " * italic(
        p[R.D]) %~% italic(Beta)(2, 2) )  )
    text(0, 11, labels = Sexpression,
         col='blue', cex=1.5, pos=4
    )
    Lexpression = as.expression(
      bquote( "L:  " * italic(
        p[R.D]==p[R]) %~% Beta(2, 2) ) ) 
    text(0, 9, labels = Lexpression,
         col='red', cex=1.5, pos=4
    )
    Wexpression = as.expression(
      bquote( "W:  " * italic("Dr. Who mixture" ) ) )
    text(0, 7, labels = Wexpression,
         col='darkgreen', cex=1.5, pos=4
    )

    nRD=rValues$DLdata['R','D']
    nND=rValues$DLdata['N','D']
    posterior.s = dbeta(pSeq, 
                    1+nRD, 
                    1+nND)
    nR=sum(rValues$DLdata['R', ])
    nN=sum(rValues$DLdata['N', ])
    posterior.l = dbeta(pSeq, 
                        2+nR, 2+nN)
    postProb = posteriorProb(priorOdds = 1, theData = rValues$DLdata)
    cat('mSplit is ', mSplit(rValues$DLdata), '\n')
    cat('mLump is ', mLump(rValues$DLdata), '\n')
    cat('DrWhoBayesFactor is ', DrWhoBayesFactor(rValues$DLdata), '\n')
    cat('postProb is ', postProb, '\n')
    posterior.w = (postProb) * posterior.s + (1-postProb) * posterior.l

    plot(pSeq, posterior.s, col='blue', type='l',
         xlab='probability', ylab='density',
         ylim=c(0,15),
         main='Posteriors') 
    lines(pSeq, posterior.l,  col='red')
    lines(pSeq, posterior.w,  col='darkgreen', lwd=2)

    points(pSeq[everyTenth], posterior.s[everyTenth], pch='S', col='blue')
    points(pSeq[everyTenth], posterior.l[everyTenth], pch='L', col='red')
    points(pSeq[everyTenth], posterior.w[everyTenth], pch='W', col='darkgreen')

    Sexpression = as.expression(
      bquote("S:  " * italic(
        p[R.D]) %~% italic(Beta)(2+.(nRD), 2+.(nND))) ) 
    text(0,11, labels = Sexpression,
         col='blue', cex=1.5, pos=4
    )
    Lexpression = as.expression(
      bquote( "L:  " * italic(
        p[R.D]==p[R]) %~% Beta(2+.(nR), 2+.(nN))) ) 
    text(0, 9, labels = Lexpression,
         col='red', cex=1.5, pos=4
    )
    Wexpression = as.expression(
      bquote( "W:  " * italic("Dr. Who mixture" ) ) )
    text(0, 7, labels = Wexpression,
         col='darkgreen', cex=1.5, pos=4
    )
  })
plotOutput('whoMixturePlot')
```

##### The Bayes Factor: posterior odds (and probability) of the "null hypothesis"

The  Bayes Factor is the ratio of these marginal probabilities of the data,
and also the ratio of posterior odds to prior odds:
\[BF = \frac{m_{Split}}{m_{Lump}} = \frac{Pr(Split|data)}{Pr(Lump|data)}
\div \frac{Pr(Split)}{Pr(Lump)}.\]

```{r}
output$BF = renderText({DrWhoBayesFactor(rValues$DLdata)})
```

In our case, the Bayes Factor is `r textOutput('BF', inline=TRUE)`.

If *Dr.Split* and *Dr.Lump* have equal prior probability (prior odds = 1),
then the posterior odds is the Bayes factor,
and  the posterior probability that *Dr.Lump* is right is

\[{\rm{Pr(}}\phi  = Lump|data) = {m_{Lump}}/({m_{Split}} + {m_{Lump}})\]

More generally, 

\[
\Pr (R|D,Who) = \Pr (Lump|data) \times \Pr (R|D,Lump) + \Pr (Split|data) \times \Pr (R|D,Split)\]

```{r}
output$bayesAverage = renderText({
  paste0('Pr(Lump) *  mLump + Pr(Split) * mSplit',
         '= ',
         signif(digits=3,
                (1/2) * mLump(rValues$DLdata) +
                  (1/2) * mSplit(rValues$DLdata))
  )
})
```
which equals  `r textOutput('bayesAverage', inline=TRUE)`.

You can adjust the prior probability and observe how the posterior probability changes:

the posterior odds that *Dr.Lump* is right is

\[{\rm{Odds}(\phi = Lump|data) = \rm{Odds(}\phi  = Lump) \times {m_{Lump}}/{m_{Split}}}\]

